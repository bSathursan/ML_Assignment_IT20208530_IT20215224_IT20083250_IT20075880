{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KithusshandR/ML_Assignment2_IT19029832_IT19241760_IT19121802/blob/Development/ML_Assignment02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XQEnq6qEqVj"
      },
      "source": [
        "# Import Necessary Libraries\n",
        "\n",
        "The nltk library to proecess the text and the pandas library to load the data are loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GXcL-kvC-b7J"
      },
      "outputs": [],
      "source": [
        "# Import the Natural Language Toolkit (nltk) and the Pandas library (pd)\n",
        "import nltk\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data\n",
        "\n",
        "Load the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary library to load data from Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the Google Drive to access the dataset\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load the dataset from the specified file location in Google Drive\n",
        "dataset = pd.read_csv('/content/gdrive/MyDrive/content/website_classification.csv')\n",
        "\n",
        "# Print the first five rows of the dataset to verify it has been loaded correctly\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Fsz24l3UrD"
      },
      "source": [
        "# Test the model\n",
        "\n",
        "Test the model and print the accuracy of the created machine learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7yc8Dc32XN8",
        "outputId": "067adee3-11b2-4823-ea01-148c7cce57b5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Use the trained model to make predictions on the test data\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Print the predictions to the console\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkN8LyNe2Yid",
        "outputId": "5c45aec5-d148-4542-f7c9-64eef2ea2a15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([15, 14, 10,  9,  3, 14,  8, 13,  3,  6, 12,  4, 12,  3, 14,  8,  1,\n",
              "        4,  9,  8,  5,  4, 14,  5,  7,  2, 12,  7, 11,  5,  9,  7,  9,  0,\n",
              "        7,  3,  7,  2,  1,  1, 14,  2,  1,  5,  1, 11,  3, 15, 14,  5, 13,\n",
              "       15,  1, 15,  6,  9,  4,  5, 11, 13,  8,  0,  8, 15, 10,  7, 11,  4,\n",
              "       11,  2, 10,  3, 13,  8, 15,  5,  4, 12,  2,  3, 13,  1, 10,  4,  4,\n",
              "        7, 15, 15,  2,  4, 12,  3, 15,  4, 15,  2, 14, 11,  5,  9,  3,  1,\n",
              "       13,  1, 13, 14, 11, 10, 10, 12,  8,  9, 11, 13, 10, 12,  1,  3,  1,\n",
              "        7, 13,  8, 10, 11,  8, 10,  2, 15,  7,  4,  5, 14,  2,  7,  9, 13,\n",
              "       12, 14,  8, 10, 14])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print the actual label to compare with the prediction\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtELcW812o6O",
        "outputId": "e9718095-ae3a-46f2-e391-bc13039174cd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Test the Model\n",
        "# Import numpy library\n",
        "import numpy as np\n",
        "\n",
        "# Define a new text to classify as a numpy array\n",
        "new_text = np.array([\"She is very hot and sexy\"])\n",
        "\n",
        "# Transform the text into a vector using a CountVectorizer object\n",
        "new_vector = countvectorizer.transform(new_text)\n",
        "\n",
        "# Predict the class of the new text using a machine learning model and print it\n",
        "print(le.inverse_transform(model.predict(new_vector)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The Data preprocessing is used to clean the data like removeing the null values and duplicate values and prepare the dataset to train the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary NLTK libraries\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Create a WordNetLemmatizer object\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that takes a text string as input, tokenizes the text, and applies lemmatization to each word\n",
        "def tokenize(text):\n",
        "  # Convert text to lowercase\n",
        "  text = text.lower()\n",
        "\n",
        "  # Lemmatize text using the WordNetLemmatizer object\n",
        "  text = lemmartizer.lemmatize(text)\n",
        "\n",
        "  # Remove non-alphanumeric characters and digits from text using a regular expression\n",
        "  text = re.sub(r'\\W+|\\d+|_', ' ', text)\n",
        "\n",
        "  # Tokenize the text into individual words using NLTK's word_tokenize() function\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  # Return the tokenized text\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import necessary libraries and modules\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# create a set of stop words using the NLTK library for English language\n",
        "nltk_stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# manually add some additional words to the list of stop words\n",
        "nltk_stop_words.update(['she', 'doesn', 'you', 'under', 'again', 'is', 'your', 'mightn', 'might', 'just', 't', 'but', 'more', 'further', 'should', 'nor', 'can', 'ourselves', 'as', 'her', 'themselves', 'than', 're', 'what', 'of', 'shouldn', 'y', 'yourself', 'had', 'by', 'why', 'once', 'i', 'how', 'the', 'while', 'being', 'to', 'ours', 'and', 'here', 'too', 'an', 'ha', 'until', 'ain', 've', 'did', 'only', 'own', 'our', 'about', 'shan', 'are', 'need', 'no', 'with', 'some', 'wasn', 'him', 'weren', 'these', 'off', 'we', 'where', 'couldn', 'been', 'herself', 'hadn', 'were', 'could', 'each', 'a', 'or', 'my', 'himself', 'hers', 'who', 'couldn', 'because', 'whom', 'into', 'doesn', 'them', 'n', 'aren', 'myself', 'out', 'during', 'up', 'few', 's', 'didn', 'was', 'after', 'me', 'its', 'before', 'have', 'now', 'when', 'that', 'it', 'most', 'yourselves', 'o', 'which', 'so', 'yours', 'wouldn', 'sha', 'below', 'down', 'does', 'such', 'would', 'they', 'itself', 'don', 'not', 'same', 'their', 'both', 'wo', 'am', 'has', 'very', 'will', 'won', 'between', 'other', 'must', 'wa', 'this', 'ma', 'those', 'he', 'they', 'here', 'there', 'we'])\n",
        "\n",
        "# create an instance of the CountVectorizer class, and pass the set of stop words to it\n",
        "countvectorizer = CountVectorizer(stop_words=nltk_stop_words)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Other Classification Algorithms\n",
        "Evaluate the classification on other machine learning classification algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary library to use the Random Forest Classifier algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the Random Forest Classifier algorithm\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the trained Random Forest Classifier model to predict the target variable (y) for the test dataset (X_test)\n",
        "prediction = rfc.predict(X_test)\n",
        "\n",
        "print('The model training accuracy:', round(accuracy_score(y_train, rfc.predict(X_train)),5))\n",
        "print('The model Testing accuracy:', round(accuracy_score(y_test, prediction),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for creating a confusion matrix visualization to evaluate machine learning model performance and accuracy\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix using the predicted values from the test data and the actual values of the test data\n",
        "confusion_matrix(y_test, rfc.predict(X_test))\n",
        "\n",
        "# Create a heatmap of the confusion matrix, transposing it to display the true and predicted labels in the correct orientation\n",
        "sns.heatmap(confusion_matrix(y_test, rfc.predict(X_test)).T, square=False, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=dataset.Category.unique(),\n",
        "            yticklabels=dataset.Category.unique())\n",
        "\n",
        "# Add labels to the x and y axes of the plot\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qVirxrbJIjv4",
        "outputId": "22e09a84-742a-4f60-97e4-a68f76403cdc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(p=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(p=16)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(p=16)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import the necessary library to use the K Neighbors Classifier algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create an instance of the K Neighbors Classifier algorithm\n",
        "neigh = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=16)\n",
        "\n",
        "# Train the model on the training data\n",
        "neigh.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfWH--JSI4po",
        "outputId": "96d749ae-906e-4584-eb07-84969ea9312a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mode training accuracy: 0.75691\n",
            "The model Testing accuracy: 0.57447\n"
          ]
        }
      ],
      "source": [
        "# Use the trained K Neighbors Classifier model to predict the target variable (y) for the test dataset (X_test)\n",
        "prediction = neigh.predict(X_test)\n",
        "\n",
        "print('The mode training accuracy:', round(accuracy_score(y_train, neigh.predict(X_train)),5))\n",
        "print('The model Testing accuracy:', round(accuracy_score(y_test, prediction),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for creating a confusion matrix visualization to evaluate machine learning model performance and accuracy\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix using the predicted values from the test data and the actual values of the test data\n",
        "confusion_matrix(y_test, neigh.predict(X_test))\n",
        "\n",
        "# Create a heatmap of the confusion matrix, transposing it to display the true and predicted labels in the correct orientation\n",
        "sns.heatmap(confusion_matrix(y_test, neigh.predict(X_test)).T, square=False, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=dataset.Category.unique(),\n",
        "            yticklabels=dataset.Category.unique())\n",
        "\n",
        "# Add labels to the x and y axes of the plot\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1XQEnq6qEqVj",
        "yKmm2tKqE4Eb",
        "TktHObkmFB28",
        "-6dO9wO0FPnm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
