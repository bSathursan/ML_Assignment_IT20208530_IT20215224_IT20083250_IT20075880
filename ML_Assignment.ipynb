{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KithusshandR/ML_Assignment2_IT19029832_IT19241760_IT19121802/blob/Development/ML_Assignment02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XQEnq6qEqVj"
      },
      "source": [
        "# Import Necessary Libraries\n",
        "\n",
        "The nltk library to proecess the text and the pandas library to load the data are loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GXcL-kvC-b7J"
      },
      "outputs": [],
      "source": [
        "# Import the Natural Language Toolkit (nltk) and the Pandas library (pd)\n",
        "import nltk\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data\n",
        "\n",
        "Load the dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis the loaded Dataset\n",
        "\n",
        "The loaded dataset is analysised to find the information about the dataset like No of row and no of columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1408, 4)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the shape of the dataset (number of rows and columns)\n",
        "shape = dataset.shape\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(f\"The dataset has {shape[0]} rows and {shape[1]} columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
            "\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Get the list of column names in the dataset\n",
        "columns = dataset.columns\n",
        "\n",
        "# Print the column names\n",
        "print(\"Column names:\")\n",
        "for col in columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d445df5-2183-4de2-a5cd-5e265b31e928\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_website_text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>official site good hotel accommodation big sav...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>expedia hotel book sites like use vacation wor...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tripadvisor hotel book sites like previously d...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cheap flights search compare flights momondo f...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bot create free account create free account si...</td>\n",
              "      <td>Travel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d445df5-2183-4de2-a5cd-5e265b31e928')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d445df5-2183-4de2-a5cd-5e265b31e928 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d445df5-2183-4de2-a5cd-5e265b31e928');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                cleaned_website_text Category\n",
              "0  official site good hotel accommodation big sav...   Travel\n",
              "1  expedia hotel book sites like use vacation wor...   Travel\n",
              "2  tripadvisor hotel book sites like previously d...   Travel\n",
              "3  cheap flights search compare flights momondo f...   Travel\n",
              "4  bot create free account create free account si...   Travel"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Remove the 'Unnamed: 0' and 'website_url' columns from the dataset\n",
        "dataset = dataset.drop('Unnamed: 0', axis=1)\n",
        "dataset = dataset.drop('website_url', axis=1)\n",
        "\n",
        "# Print the first five rows of the modified dataset\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "cleaned_website_text    object\n",
              "Category                object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the data types of the columns in the dataset\n",
        "data_types = dataset.dtypes\n",
        "\n",
        "# Print the data types of each column\n",
        "print(\"Data types:\")\n",
        "for col, dtype in data_types.iteritems():\n",
        "    print(f\"{col}: {dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Travel', 'Social Networking and Messaging', 'News',\n",
              "       'Streaming Services', 'Sports', 'Photography',\n",
              "       'Law and Government', 'Health and Fitness', 'Games', 'E-Commerce',\n",
              "       'Forums', 'Food', 'Education', 'Computers and Technology',\n",
              "       'Business/Corporate', 'Adult'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get the unique values in the 'Category' column of the dataset\n",
        "unique_categories = dataset.Category.unique()\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique categories:\")\n",
        "for category in unique_categories:\n",
        "    print(category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1408 entries, 0 to 1407\n",
            "Data columns (total 2 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   cleaned_website_text  1408 non-null   object\n",
            " 1   Category              1408 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 22.1+ KB\n"
          ]
        }
      ],
      "source": [
        "# Get information about the dataset, including the number of non-null values and data types of each column\n",
        "dataset_info = dataset.info()\n",
        "\n",
        "# Print the dataset information\n",
        "print(dataset_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary library to load data from Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the Google Drive to access the dataset\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load the dataset from the specified file location in Google Drive\n",
        "dataset = pd.read_csv('/content/gdrive/MyDrive/content/website_classification.csv')\n",
        "\n",
        "# Print the first five rows of the dataset to verify it has been loaded correctly\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Fsz24l3UrD"
      },
      "source": [
        "# Test the model\n",
        "\n",
        "Test the model and print the accuracy of the created machine learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7yc8Dc32XN8",
        "outputId": "067adee3-11b2-4823-ea01-148c7cce57b5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Use the trained model to make predictions on the test data\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "# Print the predictions to the console\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkN8LyNe2Yid",
        "outputId": "5c45aec5-d148-4542-f7c9-64eef2ea2a15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([15, 14, 10,  9,  3, 14,  8, 13,  3,  6, 12,  4, 12,  3, 14,  8,  1,\n",
              "        4,  9,  8,  5,  4, 14,  5,  7,  2, 12,  7, 11,  5,  9,  7,  9,  0,\n",
              "        7,  3,  7,  2,  1,  1, 14,  2,  1,  5,  1, 11,  3, 15, 14,  5, 13,\n",
              "       15,  1, 15,  6,  9,  4,  5, 11, 13,  8,  0,  8, 15, 10,  7, 11,  4,\n",
              "       11,  2, 10,  3, 13,  8, 15,  5,  4, 12,  2,  3, 13,  1, 10,  4,  4,\n",
              "        7, 15, 15,  2,  4, 12,  3, 15,  4, 15,  2, 14, 11,  5,  9,  3,  1,\n",
              "       13,  1, 13, 14, 11, 10, 10, 12,  8,  9, 11, 13, 10, 12,  1,  3,  1,\n",
              "        7, 13,  8, 10, 11,  8, 10,  2, 15,  7,  4,  5, 14,  2,  7,  9, 13,\n",
              "       12, 14,  8, 10, 14])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#print the actual label to compare with the prediction\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtELcW812o6O",
        "outputId": "e9718095-ae3a-46f2-e391-bc13039174cd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Test the Model\n",
        "# Import numpy library\n",
        "import numpy as np\n",
        "\n",
        "# Define a new text to classify as a numpy array\n",
        "new_text = np.array([\"She is very hot and sexy\"])\n",
        "\n",
        "# Transform the text into a vector using a CountVectorizer object\n",
        "new_vector = countvectorizer.transform(new_text)\n",
        "\n",
        "# Predict the class of the new text using a machine learning model and print it\n",
        "print(le.inverse_transform(model.predict(new_vector)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The Data preprocessing is used to clean the data like removeing the null values and duplicate values and prepare the dataset to train the machine learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning model\n",
        "\n",
        "Here we use teh Multinomial Naive Bayes Model to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary NLTK libraries\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Create a WordNetLemmatizer object\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function that takes a text string as input, tokenizes the text, and applies lemmatization to each word\n",
        "def tokenize(text):\n",
        "  # Convert text to lowercase\n",
        "  text = text.lower()\n",
        "\n",
        "  # Lemmatize text using the WordNetLemmatizer object\n",
        "  text = lemmartizer.lemmatize(text)\n",
        "\n",
        "  # Remove non-alphanumeric characters and digits from text using a regular expression\n",
        "  text = re.sub(r'\\W+|\\d+|_', ' ', text)\n",
        "\n",
        "  # Tokenize the text into individual words using NLTK's word_tokenize() function\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  # Return the tokenized text\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import necessary libraries and modules\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# create a set of stop words using the NLTK library for English language\n",
        "nltk_stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# manually add some additional words to the list of stop words\n",
        "nltk_stop_words.update(['she', 'doesn', 'you', 'under', 'again', 'is', 'your', 'mightn', 'might', 'just', 't', 'but', 'more', 'further', 'should', 'nor', 'can', 'ourselves', 'as', 'her', 'themselves', 'than', 're', 'what', 'of', 'shouldn', 'y', 'yourself', 'had', 'by', 'why', 'once', 'i', 'how', 'the', 'while', 'being', 'to', 'ours', 'and', 'here', 'too', 'an', 'ha', 'until', 'ain', 've', 'did', 'only', 'own', 'our', 'about', 'shan', 'are', 'need', 'no', 'with', 'some', 'wasn', 'him', 'weren', 'these', 'off', 'we', 'where', 'couldn', 'been', 'herself', 'hadn', 'were', 'could', 'each', 'a', 'or', 'my', 'himself', 'hers', 'who', 'couldn', 'because', 'whom', 'into', 'doesn', 'them', 'n', 'aren', 'myself', 'out', 'during', 'up', 'few', 's', 'didn', 'was', 'after', 'me', 'its', 'before', 'have', 'now', 'when', 'that', 'it', 'most', 'yourselves', 'o', 'which', 'so', 'yours', 'wouldn', 'sha', 'below', 'down', 'does', 'such', 'would', 'they', 'itself', 'don', 'not', 'same', 'their', 'both', 'wo', 'am', 'has', 'very', 'will', 'won', 'between', 'other', 'must', 'wa', 'this', 'ma', 'those', 'he', 'they', 'here', 'there', 'we'])\n",
        "\n",
        "# create an instance of the CountVectorizer class, and pass the set of stop words to it\n",
        "countvectorizer = CountVectorizer(stop_words=nltk_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the pandas and CountVectorizer libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create a CountVectorizer object with English stop words\n",
        "countvectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the CountVectorizer object to the cleaned_website_text column of the dataset\n",
        "dtm = countvectorizer.fit_transform(dataset['cleaned_website_text'])\n",
        "\n",
        "# Convert the sparse matrix output of CountVectorizer to a pandas DataFrame\n",
        "dtm = pd.DataFrame(dtm.toarray(), columns=countvectorizer.vocabulary_.keys(), index=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the shape of the document-term matrix\n",
        "dtm_shape = dtm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the preprocessing module from scikit-learn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder object to the Category column of the dataset\n",
        "# and transform the categories into numerical labels\n",
        "labels = le.fit_transform(dataset.Category)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the encoded labels\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the train_test_split function from scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# The 'dtm' variable contains the feature matrix, and 'lable' contains the labels\n",
        "# The 'train_size' parameter specifies the proportion of the data to use for training\n",
        "# The 'test_size' parameter specifies the proportion of the data to use for testing\n",
        "# The 'random_state' parameter sets the seed for the random number generator\n",
        "# The 'stratify' parameter ensures that the class distribution is roughly equal\n",
        "X_train, X_test, y_train, y_test = train_test_split(dtm, lable, \n",
        "                                     train_size = 0.9, \n",
        "                                     test_size = 0.1, \n",
        "                                     random_state = 100,\n",
        "                                     stratify = lable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Other Classification Algorithms\n",
        "Evaluate the classification on other machine learning classification algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary library to use the Random Forest Classifier algorithm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create an instance of the Random Forest Classifier algorithm\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Train the model on the training data\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the trained Random Forest Classifier model to predict the target variable (y) for the test dataset (X_test)\n",
        "prediction = rfc.predict(X_test)\n",
        "\n",
        "print('The model training accuracy:', round(accuracy_score(y_train, rfc.predict(X_train)),5))\n",
        "print('The model Testing accuracy:', round(accuracy_score(y_test, prediction),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for creating a confusion matrix visualization to evaluate machine learning model performance and accuracy\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix using the predicted values from the test data and the actual values of the test data\n",
        "confusion_matrix(y_test, rfc.predict(X_test))\n",
        "\n",
        "# Create a heatmap of the confusion matrix, transposing it to display the true and predicted labels in the correct orientation\n",
        "sns.heatmap(confusion_matrix(y_test, rfc.predict(X_test)).T, square=False, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=dataset.Category.unique(),\n",
        "            yticklabels=dataset.Category.unique())\n",
        "\n",
        "# Add labels to the x and y axes of the plot\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary library to use the Decision Tree Regressor algorithm\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "  \n",
        "# Create an instance of the Decision Tree Regressor algorithm\n",
        "regressor = DecisionTreeRegressor() \n",
        "\n",
        "# Train the model on the training data\n",
        "regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the trained Decision Tree Regressor model to predict the target variable (y) for the test dataset (X_test)\n",
        "prediction = regressor.predict(X_test)\n",
        "\n",
        "print('The mode training accuracy:', round(accuracy_score(y_train, regressor.predict(X_train)),5))\n",
        "print('The model Testing accuracy:', round(accuracy_score(y_test, prediction),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for creating a confusion matrix visualization to evaluate machine learning model performance and accuracy\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix using the predicted values from the test data and the actual values of the test data\n",
        "confusion_matrix(y_test, regressor.predict(X_test))\n",
        "\n",
        "# Create a heatmap of the confusion matrix, transposing it to display the true and predicted labels in the correct orientation\n",
        "sns.heatmap(confusion_matrix(y_test, regressor.predict(X_test)).T, square=False, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=dataset.Category.unique(),\n",
        "            yticklabels=dataset.Category.unique())\n",
        "\n",
        "# Add labels to the x and y axes of the plot\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qVirxrbJIjv4",
        "outputId": "22e09a84-742a-4f60-97e4-a68f76403cdc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(p=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(p=16)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(p=16)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import the necessary library to use the K Neighbors Classifier algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create an instance of the K Neighbors Classifier algorithm\n",
        "neigh = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=16)\n",
        "\n",
        "# Train the model on the training data\n",
        "neigh.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfWH--JSI4po",
        "outputId": "96d749ae-906e-4584-eb07-84969ea9312a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mode training accuracy: 0.75691\n",
            "The model Testing accuracy: 0.57447\n"
          ]
        }
      ],
      "source": [
        "# Use the trained K Neighbors Classifier model to predict the target variable (y) for the test dataset (X_test)\n",
        "prediction = neigh.predict(X_test)\n",
        "\n",
        "print('The mode training accuracy:', round(accuracy_score(y_train, neigh.predict(X_train)),5))\n",
        "print('The model Testing accuracy:', round(accuracy_score(y_test, prediction),5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries for creating a confusion matrix visualization to evaluate machine learning model performance and accuracy\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "\n",
        "# Create the confusion matrix using the predicted values from the test data and the actual values of the test data\n",
        "confusion_matrix(y_test, neigh.predict(X_test))\n",
        "\n",
        "# Create a heatmap of the confusion matrix, transposing it to display the true and predicted labels in the correct orientation\n",
        "sns.heatmap(confusion_matrix(y_test, neigh.predict(X_test)).T, square=False, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=dataset.Category.unique(),\n",
        "            yticklabels=dataset.Category.unique())\n",
        "\n",
        "# Add labels to the x and y axes of the plot\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1XQEnq6qEqVj",
        "yKmm2tKqE4Eb",
        "TktHObkmFB28",
        "-6dO9wO0FPnm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
